{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook is creating synthetic data with the temperature varying as well as the radius according the flame spreading model\n",
    "\n",
    "### No emmission from the rest of the star and putting the hotspot close to the pole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/=============================================\\\n",
      "| X-PSI: X-ray Pulse Simulation and Inference |\n",
      "|---------------------------------------------|\n",
      "|                Version: 2.0.0               |\n",
      "|---------------------------------------------|\n",
      "|      https://xpsi-group.github.io/xpsi      |\n",
      "\\=============================================/\n",
      "\n",
      "Imported GetDist version: 1.4\n",
      "Imported nestcheck version: 0.2.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "\n",
    "\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.ticker import MultipleLocator, AutoLocator, AutoMinorLocator\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import cm\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import xpsi\n",
    "\n",
    "from xpsi import Parameter\n",
    "\n",
    "from scipy.interpolate import Akima1DInterpolator\n",
    "\n",
    "\n",
    "from xpsi.global_imports import _c, _G, _dpr, gravradius, _csq, _km, _2pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'HotRegion' has no attribute 'super_colatitude'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1212085/2788056646.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxpsi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHotRegion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuper_colatitude\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'HotRegion' has no attribute 'super_colatitude'"
     ]
    }
   ],
   "source": [
    "xpsi.HotRegion.super_colatitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"figure.facecolor\": \"lightgray\",\n",
    "                    \"axes.facecolor\": \"lightgray\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kev_kelvin(x):\n",
    "    return np.log10(x*1000./(8.61733034*(10.**-5)))\n",
    "\n",
    "def kelvin_kev(x):\n",
    "    return (8.61733034*(10.**(x-5)))/1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kev_kelvin(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kev_kelvin(0.16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_burst=np.array([ 2.,  3.,  4.,  5.,  7., 10., 11., 12., 13., 15., 16., 17., 18.,\n",
    "       20., 21., 22., 24., 25., 26., 27.])\n",
    "\n",
    "\n",
    "# Importing data for burst generic burst\n",
    "\n",
    "generic_burst=np.loadtxt(\"../../generic_burst/Burst_count.txt\")\n",
    "generic_time=np.loadtxt(\"../../generic_burst/Burst_time.txt\")\n",
    "\n",
    "pulse_burst5=np.loadtxt(\"../../generic_burst/pulses/pulseburst_5.txt\")\n",
    "\n",
    "counts_burst5=np.loadtxt(\"../../generic_burst/counts/countsburst_5.txt\")\n",
    "\n",
    "generic_pulse=np.zeros((28, 16))\n",
    "generic_counts=np.zeros((17,))\n",
    "for k in good_burst:\n",
    "    k=int(k)\n",
    "    generic_pulse+=np.loadtxt(\"../../generic_burst/pulses/pulseburst_{}.txt\".format(k))\n",
    "    generic_counts+=np.loadtxt(\"../../generic_burst/counts/countsburst_{}.txt\".format(k))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperature\n",
    "## Obtain from Zach's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing temperature obtained form Zach\n",
    "\n",
    "temp_zach=np.loadtxt(\"../../temperature.dat\")\n",
    "time_zach=np.loadtxt(\"../../time.dat\")\n",
    "\n",
    "z_burst=np.loadtxt(\"../../z_burst.dat\")\n",
    "z_time=np.loadtxt(\"../../z_time.da\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(z_time,z_burst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "duration=150.\n",
    "b_bin=0.25\n",
    "l=int(duration/b_bin)\n",
    "\n",
    "f=interp1d(time_zach, temp_zach)\n",
    "\n",
    "tim=np.linspace(0,duration,l)\n",
    "\n",
    "temperature=np.log10(f(tim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generating see and saving for future use\n",
    "# from random import randint\n",
    "# seed=np.array(())\n",
    "# for i in range(l):\n",
    "#     seed=np.append(seed,randint(0, 100000))\n",
    "#     #print(i)\n",
    "# np.savetxt(\"../../seed/seed1.dat\",seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed=np.loadtxt(\"../../seed/seed1.dat\")\n",
    "seed=np.loadtxt(\"../../seed/seed1.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt(\"time_bins\",tim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(tim, seed,\"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "temperature_kev=kelvin_kev(temperature)\n",
    "\n",
    "fig, ax=plt.subplots(1,2,figsize=(15,5))\n",
    "ax[0].plot(tim, temperature_kev,\"k\")\n",
    "ax[1].plot(tim, temperature,\"k\")\n",
    "ax[0].set_xlabel(\"Time (s)\")\n",
    "ax[0].set_ylabel(\"Temperature (keV)\")\n",
    "ax[1].set_xlabel(\"Time (s)\")\n",
    "ax[1].set_ylabel(\"Temperature (kelvin)\")\n",
    "#ax[1].set_yscale(log\")\n",
    "#plt.savefig(\"images/Temperature_case1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,1)\n",
    "ax.plot(tim, temperature_kev,\"k\")\n",
    "#plt.plot(tim, temperature,\"k\")\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"Temperature (keV)\")\n",
    "#plt.set_xlabel(\"Time (s)\")\n",
    "anchored_text1 = AnchoredText(\"Case1\",loc=1)\n",
    "#ax[1].add_artist(anchored_text2)\n",
    "ax.add_artist(anchored_text1)\n",
    "\n",
    "#plt.savefig(\"images/Temperature_case1.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This temperature profile is the GS-1826 temperature profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit_sin(x, y):\n",
    "    '''Fit sin to the input time sequence, and return fitting parameters \"amp\", \"omega\", \"phase\", \"offset\", \"freq\", \"period\" and \"fitfunc\"'''\n",
    "\n",
    "    ###### Importing parameters\n",
    "    \n",
    "    ff = np.fft.fftfreq(len(x), (x[1]-x[0]))   # assume uniform spacing\n",
    "    Fyy = abs(np.fft.fft(y))\n",
    "    \n",
    "    \n",
    "    ##### Inititial guess\n",
    "    \n",
    "    guess_freq =abs(ff[np.argmax(Fyy[1:])+1])   # excluding the zero frequency \"peak\", which is related to offset\n",
    "    guess_amp = np.std(y) * 2.**0.5\n",
    "    guess_offset = np.mean(y)\n",
    "    guess = np.array([guess_amp, 2.*np.pi*guess_freq, 0., guess_offset])\n",
    "    \n",
    "    #### Fitting now \n",
    "\n",
    "    def sinfunc(t, A, w, p, c):  \n",
    "        return A * np.sin(w*t + p) + c\n",
    "    \n",
    "    \n",
    "    popt, pcov = scipy.optimize.curve_fit(sinfunc, x, y, p0=guess)\n",
    "    A, w, p, c = popt\n",
    "    #print(popt)\n",
    "    f = w/(2.*np.pi)\n",
    "    fitfunc = lambda t: A * np.sin(w*t + p) + c\n",
    "    return {\"amp\": A, \"omega\": w, \"phase\": p, \"offset\": c, \"freq\": f, \"period\": 1./f, \"fitfunc\": fitfunc, \"maxcov\": np.max(pcov), \"rawres\": (guess,popt,pcov)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(t,a,b):\n",
    "    return a+b*np.sin(t*resburst_generic[\"omega\"]+resburst_generic[\"phase\"])\n",
    "\n",
    "def fitburst(t,a,b):\n",
    "    return a+b*np.sin(t*resburst10[\"omega\"]+resburst10[\"phase\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"../../ST_modules/\"\n",
    "sys.path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['text.usetex'] = False\n",
    "rcParams['font.size'] = 14.0\n",
    "\n",
    "def veneer(x, y, axes, lw=1.0, length=8):\n",
    "    \"\"\" Make the plots a little more aesthetically pleasing. \"\"\"\n",
    "    if x is not None:\n",
    "        if x[1] is not None:\n",
    "            axes.xaxis.set_major_locator(MultipleLocator(x[1]))\n",
    "        if x[0] is not None:\n",
    "            axes.xaxis.set_minor_locator(MultipleLocator(x[0]))\n",
    "    else:\n",
    "        axes.xaxis.set_major_locator(AutoLocator())\n",
    "        axes.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "\n",
    "    if y is not None:\n",
    "        if y[1] is not None:\n",
    "            axes.yaxis.set_major_locator(MultipleLocator(y[1]))\n",
    "        if y[0] is not None:\n",
    "            axes.yaxis.set_minor_locator(MultipleLocator(y[0]))\n",
    "    else:\n",
    "        axes.yaxis.set_major_locator(AutoLocator())\n",
    "        axes.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "\n",
    "    axes.tick_params(which='major', colors='black', length=length, width=lw)\n",
    "    axes.tick_params(which='minor', colors='black', length=int(length/2), width=lw)\n",
    "    plt.setp(axes.spines.values(), linewidth=lw, color='black')\n",
    "\n",
    "def plot_one_pulse(pulse, x, label=r'Counts', cmap=cm.magma, vmin=None, vmax=None):\n",
    "    \"\"\" Plot a pulse resolved over a single rotational cycle. \"\"\"\n",
    "\n",
    "    fig = plt.figure(figsize = (7,7))\n",
    "\n",
    "    gs = gridspec.GridSpec(1, 2, width_ratios=[50,1])\n",
    "    ax = plt.subplot(gs[0])\n",
    "    ax_cb = plt.subplot(gs[1])\n",
    "\n",
    "    profile = ax.pcolormesh(x,\n",
    "                             _data.channels,\n",
    "                             pulse,\n",
    "                             vmin = vmin,\n",
    "                             vmax = vmax,\n",
    "                             cmap = cmap,\n",
    "                             linewidth = 0,\n",
    "                             rasterized = True)\n",
    "\n",
    "    profile.set_edgecolor('face')\n",
    "\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    #ax.set_ylim(0,50)\n",
    "    #ax.set_yscale('log')\n",
    "    ax.set_ylabel(r'Channel')\n",
    "    ax.set_xlabel(r'Phase')\n",
    "\n",
    "    cb = plt.colorbar(profile,\n",
    "                      cax = ax_cb)\n",
    "\n",
    "    cb.set_label(label=label, labelpad=25)\n",
    "    cb.solids.set_edgecolor('face')\n",
    "\n",
    "    veneer((0.05, 0.2), (None, None), ax)\n",
    "\n",
    "    plt.subplots_adjust(wspace = 0.025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=1\n",
    "b=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomInstrument(xpsi.Instrument):\n",
    "    \"\"\" A model of the RXTE-PCA telescope response. \"\"\"\n",
    "\n",
    "    def __call__(self, signal, *args):\n",
    "        \"\"\" Overwrite base just to show it is possible.\n",
    "\n",
    "        We loaded only a submatrix of the total instrument response\n",
    "        matrix into memory, so here we can simplify the method in the\n",
    "        base class.\n",
    "\n",
    "        \"\"\"\n",
    "        matrix = self.construct_matrix()\n",
    "\n",
    "        self._folded_signal = np.dot(matrix, signal)\n",
    "\n",
    "        return self._folded_signal\n",
    "\n",
    "    @classmethod\n",
    "    def from_SWG(cls, matrix, edges, channel_edges=None,min_matrix=3,max_matrix=30):\n",
    "        try:\n",
    "             if channel_edges:\n",
    "                channel_edges = np.loadtxt(channel_edges, dtype=np.double)\n",
    "        except (OSError, IOError, TypeError, ValueError):\n",
    "            print('channel_edges file could not be loaded.')\n",
    "        RSP = np.loadtxt(matrix, dtype=np.double)\n",
    "        RSP = RSP.transpose()\n",
    "        edges = (np.loadtxt(edges, dtype=np.double))\n",
    "\n",
    "        #Sub response matrice to select\n",
    "        matrix=RSP[min_matrix:max_matrix,0:301]\n",
    "        channels = np.arange(min_matrix, max_matrix)\n",
    "        \n",
    "        return cls(matrix, edges, channels, channel_edges[min_matrix:max_matrix+1,-2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from Nicer_CustomInstrument import CustomInstrument\n",
    "\n",
    "# Instrument = CustomInstrument.from_response_files(ARF = '../Settings/nicer_v1.01_arf.txt',\n",
    "#                                              RMF = '../Settings/nicer_v1.01_rmf_matrix.txt',\n",
    "#                                              max_input = 1500,\n",
    "#                                              min_input = 0,\n",
    "#                                              chan_min=a,\n",
    "#                                              chan_max=b,\n",
    "#                                              channel_edges = '../Settings/nicer_v1.01_rmf_energymap.txt')\n",
    "\n",
    "#from CustomInstrument import CustomInstrument\n",
    "\n",
    "Instrument = CustomInstrument.from_SWG(matrix=\"../../Instrument_settings/RSP_burst10.txt\",\n",
    "                                edges=\"../../Instrument_settings/energy_edges.txt\",\n",
    "                                channel_edges=\"../../Instrument_settings/Energymap.txt\",\n",
    "                                min_matrix=a,\n",
    "                                max_matrix=b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomInterstellar(xpsi.Interstellar):\n",
    "    \"\"\" Apply interstellar attenuation. \"\"\"\n",
    "\n",
    "    def __init__(self, energies, attenuation, bounds, values = {}):\n",
    "\n",
    "        assert len(energies) == len(attenuation), 'Array length mismatch.'\n",
    "\n",
    "        self._lkp_energies = energies # for lookup\n",
    "        self._lkp_attenuation = attenuation # for lookup\n",
    "\n",
    "        N_H = Parameter('column_density',\n",
    "                        strict_bounds = (0.0,10.0),\n",
    "                        bounds = bounds.get('column_density', None),\n",
    "                        doc = 'Units of 10^20 cm^-2.',\n",
    "                        symbol = r'$N_{\\rm H}$',\n",
    "                        value = values.get('column_density', None))\n",
    "\n",
    "        self._interpolator = Akima1DInterpolator(self._lkp_energies,\n",
    "                                                 self._lkp_attenuation)\n",
    "        self._interpolator.extrapolate = True\n",
    "\n",
    "        super(CustomInterstellar, self).__init__(N_H)\n",
    "\n",
    "    def attenuation(self, energies):\n",
    "        \"\"\" Interpolate the attenuation coefficients.\n",
    "\n",
    "        Useful for post-processing. \n",
    "\n",
    "        \"\"\"\n",
    "        return self._interpolate(energies)**(self['column_density']/0.4)\n",
    "\n",
    "    def _interpolate(self, energies):\n",
    "        \"\"\" Helper. \"\"\"\n",
    "        _att = self._interpolator(energies)\n",
    "        _att[_att < 0.0] = 0.0\n",
    "        return _att\n",
    "\n",
    "    @classmethod\n",
    "    def from_SWG(cls, path, **kwargs):\n",
    "        \"\"\" Load attenuation file from the NICER SWG. \"\"\"\n",
    "\n",
    "        temp = np.loadtxt(path, dtype=np.double)\n",
    "\n",
    "        energies = temp[:,0]\n",
    "\n",
    "        attenuation = temp[:,2]\n",
    "\n",
    "        return cls(energies, attenuation, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interstellar = CustomInterstellar.from_SWG(\"../../ISM/ISM_frac.txt\",\n",
    "                                           bounds = dict(column_density = (0.0,10.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xpsi.likelihoods.default_background_marginalisation import eval_marginal_likelihood\n",
    "from xpsi.likelihoods.default_background_marginalisation import precomputation\n",
    "\n",
    "class CustomSignal(xpsi.Signal):\n",
    "    \"\"\"\n",
    "\n",
    "    A custom calculation of the logarithm of the likelihood.\n",
    "    We extend the :class:`~xpsi.Signal.Signal` class to make it callable.\n",
    "    We overwrite the body of the __call__ method. The docstring for the\n",
    "    abstract method is copied.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, workspace_intervals = 1000, epsabs = 0, epsrel = 1.0e-8,\n",
    "                 epsilon = 1.0e-3, sigmas = 10.0, support = None, **kwargs):\n",
    "        \"\"\" Perform precomputation.\n",
    "\n",
    "        :params ndarray[m,2] support:\n",
    "            Prior support bounds for background count rate variables in the\n",
    "            :math:`m` instrument channels, where the lower bounds must be zero\n",
    "            or positive, and the upper bounds must be positive and greater than\n",
    "            the lower bound. Alternatively, setting the an upper bounds as\n",
    "            negative means the prior support is unbounded and the flat prior\n",
    "            density functions per channel are improper. If ``None``, the lower-\n",
    "            bound of the support for each channel is zero but the prior is\n",
    "            unbounded.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        super(CustomSignal, self).__init__(**kwargs)\n",
    "\n",
    "        try:\n",
    "            self._precomp = precomputation(self._data.counts.astype(np.int32))\n",
    "        except AttributeError:\n",
    "            print('Warning: No data... can synthesise data but cannot evaluate a '\n",
    "                  'likelihood function.')\n",
    "        else:\n",
    "            self._workspace_intervals = workspace_intervals\n",
    "            self._epsabs = epsabs\n",
    "            self._epsrel = epsrel\n",
    "            self._epsilon = epsilon\n",
    "            self._sigmas = sigmas\n",
    "\n",
    "            if support is not None:\n",
    "                self._support = support\n",
    "            else:\n",
    "                self._support = -1.0 * np.ones((self._data.counts.shape[0],2))\n",
    "                self._support[:,0] = 0.0\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        self.loglikelihood, self.expected_counts, self.background_signal = \\\n",
    "                eval_marginal_likelihood(self._data.exposure_time,\n",
    "                                          self._data.phases,\n",
    "                                          self._data.counts,\n",
    "                                          self._signals,\n",
    "                                          self._phases,\n",
    "                                          self._shifts,\n",
    "                                          self._precomp,\n",
    "                                          self._support,\n",
    "                                          self._workspace_intervals,\n",
    "                                          self._epsabs,\n",
    "                                          self._epsrel,\n",
    "                                          self._epsilon,\n",
    "                                          self._sigmas,\n",
    "                                          kwargs.get('llzero'),\n",
    "                                          allow_negative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacetime = xpsi.Spacetime.fixed_spin(314.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = dict(distance = (0.1, 1.0),                     # (Earth) distance\n",
    "                mass = (1.0, 3.0),                       # mass\n",
    "                radius = (3.0 * gravradius(1.0), 16.0),  # equatorial radius\n",
    "                cos_inclination = (0.0, 1.0))      # (Earth) inclination to rotation axis\n",
    "\n",
    "spacetime = xpsi.Spacetime(bounds=bounds, values=dict(frequency=314.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = dict(super_colatitude = (None, None),\n",
    "              super_radius = (None, None),\n",
    "              phase_shift = (-0.25, 0.75),\n",
    "              super_temperature = (None, None))\n",
    "\n",
    "# a simple circular, simply-connected spot\n",
    "primary = xpsi.HotRegion(bounds=bounds,\n",
    "                            values={}, # no initial values and no derived/fixed\n",
    "                            symmetry=True,\n",
    "                            omit=False,\n",
    "                            cede=False,\n",
    "                            concentric=False,\n",
    "                            sqrt_num_cells=32,\n",
    "                            min_sqrt_num_cells=10,\n",
    "                            max_sqrt_num_cells=64,\n",
    "                            num_leaves=100,\n",
    "                            num_rays=200,\n",
    "                            prefix='p') # unique prefix needed because >1 instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = dict(super_colatitude = (None, None),\n",
    "              super_radius = (None, None),\n",
    "              phase_shift = (-0.25, 0.75),\n",
    "              super_temperature = (None, None))\n",
    "\n",
    "# a simple circular, simply-connected spot\n",
    "hot = xpsi.HotRegion(bounds=bounds,\n",
    "                            values={}, # no initial values and no derived/fixed\n",
    "                            symmetry=True,\n",
    "                            omit=False,\n",
    "                            cede=False,\n",
    "                            concentric=False,\n",
    "                            sqrt_num_cells=32,\n",
    "                            min_sqrt_num_cells=10,\n",
    "                            max_sqrt_num_cells=64,\n",
    "                            num_leaves=100,\n",
    "                            num_rays=200,\n",
    "                            is_antiphased=True, \n",
    "                            prefix='h') # unique prefix needed because >1 instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "###################################################################################################################\n",
    "########################################       CustomPhotosphere for J1814-338      ###############################\n",
    "########################################                  Analysis  (STU)           ###############################\n",
    "########################################    Using numerical atmosphere for hot NS)  ###############################\n",
    "###################################################################################################################\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import xpsi\n",
    "\n",
    "class CustomPhotosphere(xpsi.Photosphere):\n",
    "    \"\"\"\n",
    "    CustomPhotosphere made for bursting atmosphere like XTE J1814-338.\n",
    "\n",
    "    A photosphere extension to preload the numerical  diluted atmosphere.\n",
    "\n",
    "    Using hot diluted atmosphere computed by Siem .\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    @xpsi.Photosphere.hot_atmosphere.setter\n",
    "    def hot_atmosphere(self, path):\n",
    "        Siem = np.loadtxt(path, dtype=np.double)\n",
    "\n",
    "        # This is to get the number of value computed\n",
    "\n",
    "        E_range=len(set(Siem[:,0]))\n",
    "        mu_range=len(set(Siem[:,1]))\n",
    "        T_range=len(set(Siem[:,3]))\n",
    "        g_range=len(set(Siem[:,4]))\n",
    "\n",
    "\n",
    "\n",
    "#         logT = np.zeros(35)\n",
    "#         logg = np.zeros(14)\n",
    "#         mu = np.zeros(67)\n",
    "#         logE = np.zeros(166)\n",
    "\n",
    "        logT = np.zeros(T_range)\n",
    "        logg = np.zeros(g_range)\n",
    "        mu = np.zeros(mu_range)\n",
    "        logE = np.zeros(E_range)\n",
    "\n",
    "\n",
    "        reorder_buf = np.zeros((T_range,g_range,mu_range,E_range))\n",
    "\n",
    "        index = 0\n",
    "        for i in range(reorder_buf.shape[0]):\n",
    "            for j in range(reorder_buf.shape[1]):\n",
    "                for k in range(reorder_buf.shape[3]):\n",
    "                    for l in range(reorder_buf.shape[2]):\n",
    "                        logT[i] = Siem[index,3]\n",
    "                        logg[j] = Siem[index,4]\n",
    "                        logE[k] = Siem[index,0]\n",
    "                        mu[reorder_buf.shape[2] - l - 1] = Siem[index,1]\n",
    "                        reorder_buf[i,j,reorder_buf.shape[2] - l - 1,k] = 10.0**(Siem[index,2])\n",
    "                        index += 1\n",
    "\n",
    "        buf = np.zeros(np.prod(reorder_buf.shape))\n",
    "\n",
    "        bufdex = 0\n",
    "        for i in range(reorder_buf.shape[0]):\n",
    "            for j in range(reorder_buf.shape[1]):\n",
    "                for k in range(reorder_buf.shape[2]):\n",
    "                    for l in range(reorder_buf.shape[3]):\n",
    "                        buf[bufdex] = reorder_buf[i,j,k,l]; bufdex += 1\n",
    "\n",
    "        self._hot_atmosphere = (logT, logg, mu, logE, buf)\n",
    "        \n",
    "        \n",
    "    @xpsi.Photosphere.elsewhere_atmosphere.setter\n",
    "    def elsewhere_atmosphere(self, path):\n",
    "        Siem = np.loadtxt(path, dtype=np.double)\n",
    "\n",
    "        # This is to get the number of value computed\n",
    "\n",
    "        E_range=len(set(Siem[:,0]))\n",
    "        mu_range=len(set(Siem[:,1]))\n",
    "        T_range=len(set(Siem[:,3]))\n",
    "        g_range=len(set(Siem[:,4]))\n",
    "\n",
    "\n",
    "\n",
    "#         logT = np.zeros(35)\n",
    "#         logg = np.zeros(14)\n",
    "#         mu = np.zeros(67)\n",
    "#         logE = np.zeros(166)\n",
    "\n",
    "        logT = np.zeros(T_range)\n",
    "        logg = np.zeros(g_range)\n",
    "        mu = np.zeros(mu_range)\n",
    "        logE = np.zeros(E_range)\n",
    "\n",
    "\n",
    "        reorder_buf = np.zeros((T_range,g_range,mu_range,E_range))\n",
    "\n",
    "        index = 0\n",
    "        for i in range(reorder_buf.shape[0]):\n",
    "            for j in range(reorder_buf.shape[1]):\n",
    "                for k in range(reorder_buf.shape[3]):\n",
    "                    for l in range(reorder_buf.shape[2]):\n",
    "                        logT[i] = Siem[index,3]\n",
    "                        logg[j] = Siem[index,4]\n",
    "                        logE[k] = Siem[index,0]\n",
    "                        mu[reorder_buf.shape[2] - l - 1] = Siem[index,1]\n",
    "                        reorder_buf[i,j,reorder_buf.shape[2] - l - 1,k] = 10.0**(Siem[index,2])\n",
    "                        index += 1\n",
    "\n",
    "        buf = np.zeros(np.prod(reorder_buf.shape))\n",
    "\n",
    "        bufdex = 0\n",
    "        for i in range(reorder_buf.shape[0]):\n",
    "            for j in range(reorder_buf.shape[1]):\n",
    "                for k in range(reorder_buf.shape[2]):\n",
    "                    for l in range(reorder_buf.shape[3]):\n",
    "                        buf[bufdex] = reorder_buf[i,j,k,l]; bufdex += 1\n",
    "\n",
    "        self._elsewhere_atmosphere = (logT, logg, mu, logE, buf)\n",
    "\n",
    "\n",
    "    @property\n",
    "    def global_variables(self):\n",
    "        \"\"\" This method is needed if we also want to invoke the image-plane signal simulator.\n",
    "\n",
    "        The extension module compiled is surface_radiation_field/archive/local_variables/two_spots.pyx,\n",
    "        which replaces the contents of surface_radiation_field/local_variables.pyx.\n",
    "\n",
    "        \"\"\"\n",
    "        return np.array([self['h__super_colatitude'],\n",
    "                          self['h__phase_shift'] * _2pi,\n",
    "                          self['h__super_radius'],\n",
    "                          self['h__super_temperature']])#,\n",
    "                          #self['s__super_colatitude'],\n",
    "                          #(self['s__phase_shift'] + 0.5) * _2pi,\n",
    "                          #self['s__super_radius'],\n",
    "                          #self.hot.objects[1]['s__super_temperature']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import print_function, division\n",
    "\n",
    "# import numpy as np\n",
    "# import math\n",
    "\n",
    "# import xpsi\n",
    "\n",
    "# class CustomPhotosphere(xpsi.Photosphere):\n",
    "#     \"\"\" Implement method for imaging.\"\"\"\n",
    "\n",
    "#     @property\n",
    "#     def global_variables(self):\n",
    "\n",
    "#         return np.array([self['h__super_colatitude'],\n",
    "#                           self['h__phase_shift'] * _2pi,\n",
    "#                           self['h__super_radius'],\n",
    "#                           self['h__super_temperature']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds=dict(elsewhere_temperature = (5, 8))\n",
    "elsewhere=xpsi.Elsewhere(bounds=bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photosphere = CustomPhotosphere(hot = hot, elsewhere = None,#elsewhere,\n",
    "                                values=dict(mode_frequency = spacetime['frequency']))\n",
    "\n",
    "\n",
    "photosphere.hot_atmosphere=\"../../Atmosph/solarabundance.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star = xpsi.Star(spacetime = spacetime, photospheres = photosphere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import truncnorm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPrior(xpsi.Prior):\n",
    "    \"\"\" A custom (joint) prior distribution.\n",
    "\n",
    "    Source: Fictitious\n",
    "    Model variant: ST-U\n",
    "        Two single-temperature, simply-connected circular hot regions with\n",
    "        unshared parameters.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    __derived_names__ = ['compactness', 'phase_separation',]\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" Nothing to be done.\n",
    "\n",
    "        A direct reference to the spacetime object could be put here\n",
    "        for use in __call__:\n",
    "\n",
    "        .. code-block::\n",
    "\n",
    "            self.spacetime = ref\n",
    "\n",
    "        Instead we get a reference to the spacetime object through the\n",
    "        a reference to a likelihood object which encapsulates a\n",
    "        reference to the spacetime object.\n",
    "\n",
    "        \"\"\"\n",
    "        super(CustomPrior, self).__init__() # not strictly required if no hyperparameters\n",
    "\n",
    "    def __call__(self, p = None):\n",
    "        \"\"\" Evaluate distribution at ``p``.\n",
    "\n",
    "        :param list p: Model parameter values.\n",
    "\n",
    "        :returns: Logarithm of the distribution evaluated at ``p``.\n",
    "\n",
    "        \"\"\"\n",
    "        temp = super(CustomPrior, self).__call__(p)\n",
    "        if not np.isfinite(temp):\n",
    "            return temp\n",
    "\n",
    "        # based on contemporary EOS theory\n",
    "        if not self.parameters['radius'] <= 16.0:\n",
    "            return -np.inf\n",
    "\n",
    "        ref = self.parameters.star.spacetime # shortcut\n",
    "\n",
    "        # limit polar radius to try to exclude deflections >= \\pi radians\n",
    "        # due to oblateness this does not quite eliminate all configurations\n",
    "        # with deflections >= \\pi radians\n",
    "        R_p = 1.0 + ref.epsilon * (-0.788 + 1.030 * ref.zeta)\n",
    "        if R_p < 1.76 / ref.R_r_s:\n",
    "            return -np.inf\n",
    "\n",
    "        # polar radius at photon sphere for ~static star (static ambient spacetime)\n",
    "        #if R_p < 1.5 / ref.R_r_s:\n",
    "        #    return -np.inf\n",
    "\n",
    "        mu = math.sqrt(-1.0 / (3.0 * ref.epsilon * (-0.788 + 1.030 * ref.zeta)))\n",
    "\n",
    "        # 2-surface cross-section have a single maximum in |z|\n",
    "        # i.e., an elliptical surface; minor effect on support, if any,\n",
    "        # for high spin frequenies\n",
    "        if mu < 1.0:\n",
    "            return -np.inf\n",
    "\n",
    "        ref = self.parameters # redefine shortcut\n",
    "\n",
    "#         # enforce order in hot region colatitude\n",
    "#         if ref['p__super_colatitude'] > ref['s__super_colatitude']:\n",
    "#             return -np.inf\n",
    "\n",
    "#         phi = (ref['p__phase_shift'] - 0.5 - ref['s__phase_shift']) * _2pi\n",
    "\n",
    "#         ang_sep = xpsi.HotRegion.psi(ref['s__super_colatitude'],\n",
    "#                                      phi,\n",
    "#                                      ref['p__super_colatitude'])\n",
    "\n",
    "#         # hot regions cannot overlap\n",
    "#         if ang_sep < ref['p__super_radius'] + ref['s__super_radius']:\n",
    "#             return -np.inf\n",
    "\n",
    "        return 0.0\n",
    "\n",
    "    def inverse_sample(self, hypercube=None):\n",
    "        \"\"\" Draw sample uniformly from the distribution via inverse sampling. \"\"\"\n",
    "\n",
    "        to_cache = self.parameters.vector\n",
    "\n",
    "        if hypercube is None:\n",
    "            hypercube = np.random.rand(len(self))\n",
    "\n",
    "        # the base method is useful, so to avoid writing that code again:\n",
    "        _ = super(CustomPrior, self).inverse_sample(hypercube)\n",
    "\n",
    "        ref = self.parameters # shortcut\n",
    "\n",
    "        idx = ref.index('distance')\n",
    "        ref['distance'] = truncnorm.ppf(hypercube[idx], -2.0, 7.0, loc=0.3, scale=0.1)\n",
    "\n",
    "        # flat priors in cosine of hot region centre colatitudes (isotropy)\n",
    "        # support modified by no-overlap rejection condition\n",
    "        idx = ref.index('p__super_colatitude')\n",
    "        a, b = ref.get_param('p__super_colatitude').bounds\n",
    "        a = math.cos(a); b = math.cos(b)\n",
    "        ref['p__super_colatitude'] = math.acos(b + (a - b) * hypercube[idx])\n",
    "\n",
    "#         idx = ref.index('s__super_colatitude')\n",
    "#         a, b = ref.get_param('s__super_colatitude').bounds\n",
    "#         a = math.cos(a); b = math.cos(b)\n",
    "#         ref['s__super_colatitude'] = math.acos(b + (a - b) * hypercube[idx])\n",
    "\n",
    "        # restore proper cache\n",
    "        for parameter, cache in zip(ref, to_cache):\n",
    "            parameter.cached = cache\n",
    "\n",
    "        # it is important that we return the desired vector because it is\n",
    "        # automatically written to disk by MultiNest and only by MultiNest\n",
    "        return self.parameters.vector\n",
    "\n",
    "    def transform(self, p, **kwargs):\n",
    "        \"\"\" A transformation for post-processing. \"\"\"\n",
    "\n",
    "        p = list(p) # copy\n",
    "\n",
    "        # used ordered names and values\n",
    "        ref = dict(zip(self.parameters.names, p))\n",
    "\n",
    "        # compactness ratio M/R_eq\n",
    "        p += [gravradius(ref['mass']) / ref['radius']]\n",
    "\n",
    "#         # phase separation between hot regions\n",
    "#         # first some temporary variables:\n",
    "#         if ref['p__phase_shift'] < 0.0:\n",
    "#             temp_p = ref['p__phase_shift'] + 1.0\n",
    "#         else:\n",
    "#             temp_p = ref['p__phase_shift']\n",
    "\n",
    "#         temp_s = 0.5 + ref['s__phase_shift']\n",
    "\n",
    "#         if temp_s > 1.0:\n",
    "#             temp_s = temp_s - 1.0\n",
    "\n",
    "#         # now append:\n",
    "#         if temp_s >= temp_p:\n",
    "#             p += [temp_s - temp_p]\n",
    "#         else:\n",
    "#             p += [1.0 - temp_p + temp_s]\n",
    "\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = CustomPrior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import quad\n",
    "from xpsi.Interstellar import Interstellar\n",
    "from xpsi.global_imports import _keV, _k_B\n",
    "k_B_over_keV = _k_B / _keV\n",
    "\n",
    "\n",
    "class CustomBackground(xpsi.Background):\n",
    "    \"\"\"  ############         The background injected to generate synthetic data      #########################\n",
    "    \n",
    "\n",
    "    param dict bounds:\n",
    "                     Bounds of the powerlaw index and the blackbody temperature (in log 10)\n",
    "                     \n",
    "    param dict values:\n",
    "                     Values of the powerlaw index and temperature\n",
    "                     \n",
    "    \n",
    "    param obj interstellar:\n",
    "                    If  ``None``, the background is assumed to be local to the telescope.\n",
    "                    \n",
    "                    If not ``None``, the background is assumed to be defined as it might look like at the star, therefore NH correction must be applied.\n",
    "                     \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    def __init__(self, bounds, values, interstellar = None):\n",
    "\n",
    "        # Powerlaw component\n",
    "        doc = \"\"\"\n",
    "        Powerlaw spectral index.\n",
    "        \"\"\"\n",
    "        index = xpsi.Parameter('powerlaw_index',\n",
    "                                strict_bounds = (1, 4),\n",
    "                                bounds = bounds.get('powerlaw_index', None),\n",
    "                                doc = doc,\n",
    "                                symbol = r'$\\Gamma$',\n",
    "                                value = values.get('powerlaw_index', None))\n",
    "\n",
    "        # Blackbody component \n",
    "        doc = \"\"\"\n",
    "        Background black body temperature.\n",
    "        \"\"\"\n",
    "        background_temperature = xpsi.Parameter('background_BB_temperature',\n",
    "                                strict_bounds = (3, 10),\n",
    "                                bounds = bounds.get('background_BB_temperature', None),\n",
    "                                doc = doc,\n",
    "                                symbol = r'$T_{BB}$',\n",
    "                                value = values.get('background_BB_temperature', None))\n",
    "\n",
    "        \n",
    "        super(CustomBackground, self).__init__(index, background_temperature)\n",
    "        \n",
    "        # Making sure the interstellar object is form Interstall class\n",
    "        if interstellar is not None:\n",
    "            if not isinstance(interstellar, Interstellar):\n",
    "                raise TypeError('Invalid type for an interstellar object.')\n",
    "            else:\n",
    "                self._interstellar = interstellar\n",
    "        else:\n",
    "            self._interstellar = None\n",
    "\n",
    "\n",
    "    def __call__(self, energy_edges, phases):\n",
    "        \"\"\" Evaluate the incident background field. \"\"\"\n",
    "\n",
    "        G = self['powerlaw_index']\n",
    "        T = self['background_BB_temperature']\n",
    "\n",
    "        # Defining array that will be used later\n",
    "        array_pl=np.array([])\n",
    "        array_bb=np.array([])\n",
    "        \n",
    "        # KbT in keV\n",
    "        temp=k_B_over_keV * pow(10.0, T)\n",
    "        \n",
    "        # Numerical intergration  for both PL and BB\n",
    "        for i in range(len(energy_edges)-1):\n",
    "            \n",
    "            pl,_= quad(self.PowLaw, energy_edges[i], energy_edges[i+1], args=(G)) # Intergatting\n",
    "            bb,_= quad(self.BlackBody, energy_edges[i], energy_edges[i+1], args=(temp))\n",
    "            #print(pl)\n",
    "            array_pl=np.append(array_pl,pl)\n",
    "            array_bb=np.append(array_bb,bb)\n",
    "            \n",
    "            \n",
    "            \n",
    "        ######## Applying Normalization  in unit of photons/KeV/cm^2/s^1 #######\n",
    "        \n",
    "        k_pl=3.32*10**(-2) # See Krauss et al.2005: https://arxiv.org/pdf/astro-ph/0503671.pdf\n",
    "        k_bb=(1.6/0.8)**2  # See https://heasarc.gsfc.nasa.gov/docs/xanadu/xspec/manual/node137.html\n",
    "        array_pl *=k_pl\n",
    "        array_bb *=k_bb*(1.0344*10**(-3))\n",
    "        \n",
    "        \n",
    "        PL = np.zeros((energy_edges.shape[0] - 1, phases.shape[0]))\n",
    "        BB = np.zeros((energy_edges.shape[0] - 1, phases.shape[0]))\n",
    "        \n",
    "        for i in range(phases.shape[0]):\n",
    "            PL[:,i] = array_pl\n",
    "            BB[:,i] = array_bb\n",
    "            \n",
    "            \n",
    "        bkg=PL+BB\n",
    "        \n",
    "        # Apply Interstellar if not None\n",
    "        if self._interstellar is not None:\n",
    "            self._energy_mids=(energy_edges[1:]+energy_edges[:-1])/2\n",
    "            self._interstellar(self._energy_mids, bkg) # Bad coding right ? :)\n",
    "            \n",
    "\n",
    "\n",
    "        self._incident_background =bkg\n",
    "        ################### Just to see individual component: Not usefull code ##############\n",
    "        self.pl=PL\n",
    "        self.bb=BB\n",
    "# #         self.plnew=temp4\n",
    "# #         self.bbnew=temp6\n",
    "        \n",
    "    def PowLaw(self,energ, gamma):\n",
    "        \"\"\" Defining powerlaw function\n",
    "        E^-gamma\n",
    "    \n",
    "        \"\"\"\n",
    "        #self.energ=energ\n",
    "        #self.gamma=gamma\n",
    "        pl=energ**(-gamma)\n",
    "        return pl\n",
    "    \n",
    "    def BlackBody(self,energy,k):\n",
    "        \"\"\" Defining Blackbody function using xspec model\n",
    "        \n",
    "        See :https://heasarc.gsfc.nasa.gov/docs/xanadu/xspec/manual/node137.html\n",
    "\n",
    "        A(E)=E^2/(exp(E/kT)-1)\n",
    "\n",
    "        \"\"\"\n",
    "        result=(energy**2)/(np.exp(energy/k)-1)\n",
    "        #print(result)\n",
    "        return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = dict(powerlaw_index = (None, None),\n",
    "              background_BB_temperature = (None, None))\n",
    "\n",
    "background = CustomBackground(bounds=bounds,\n",
    "                             values={},\n",
    "                             interstellar=interstellar ) # use strict bounds, but do not fix/derive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynthesiseData(xpsi.Data):\n",
    "    \"\"\" Custom data container to enable synthesis. \"\"\"\n",
    "\n",
    "    def __init__(self, channels, phases, first, last):\n",
    "\n",
    "        self.channels = channels\n",
    "        self._phases = phases\n",
    "\n",
    "        try:\n",
    "            self._first = int(first)\n",
    "            self._last = int(last)\n",
    "        except TypeError:\n",
    "            raise TypeError('The first and last channels must be integers.')\n",
    "        if self._first >= self._last:\n",
    "            raise ValueError('The first channel number must be lower than the '\n",
    "                             'the last channel number.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data = SynthesiseData(np.arange(a,b), np.linspace(0.0, 1.0, 17), 0, b-a-1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xpsi.tools.synthesise import synthesise_exposure as _synthesise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesise(self,\n",
    "               exposure_time,\n",
    "               expected_background_counts,\n",
    "               #registered_background=back,\n",
    "               name='synthetic',\n",
    "               directory='./',\n",
    "               **kwargs):\n",
    "        \"\"\" Synthesise data set.\n",
    "\n",
    "        \"\"\"\n",
    "        self._expected_counts, synthetic, bkg,_= _synthesise(exposure_time,\n",
    "                                                             self._data.phases,\n",
    "                                                             self._signals,\n",
    "                                                             self._phases,\n",
    "                                                             self._shifts,\n",
    "                                                              expected_background_counts,\n",
    "                                                             self._background.registered_background)\n",
    "        \n",
    "        #print(self._signals)\n",
    "        #print()\n",
    "        try:\n",
    "            if not os.path.isdir(directory):\n",
    "                os.mkdir(directory)\n",
    "        except OSError:\n",
    "            print('Cannot create write directory.')\n",
    "            raise\n",
    "\n",
    "        np.savetxt(os.path.join(directory, name+'_realisation.dat'),\n",
    "                   synthetic,\n",
    "                   fmt = '%u')\n",
    "        \n",
    "        np.savetxt(os.path.join(directory, name+'_expectedcounts.dat'),\n",
    "                   self.expected_counts,\n",
    "                   fmt = '%.8e')\n",
    "        \n",
    "        \n",
    "        np.savetxt(os.path.join(directory, name+'photos_signal.dat'),\n",
    "                   np.array(photosphere.signal[0][0]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        self._write(self.expected_counts,\n",
    "                    filename = os.path.join(directory, name+'_expected_hreadable.dat'),\n",
    "                    fmt = '%.8e')\n",
    "\n",
    "        self._write(synthetic,\n",
    "                    filename = os.path.join(directory, name+'_realisation_hreadable.dat'),\n",
    "                    fmt = '%u')\n",
    "\n",
    "def _write(self, counts, filename, fmt):\n",
    "        \"\"\" Write to file in human readable format. \"\"\"\n",
    "\n",
    "        rows = len(self._data.phases) - 1\n",
    "        rows *= len(self._data.channels)\n",
    "\n",
    "        phases = self._data.phases[:-1]\n",
    "        array = np.zeros((rows, 3))\n",
    "\n",
    "        for i in range(counts.shape[0]):\n",
    "            for j in range(counts.shape[1]):\n",
    "                array[i*len(phases) + j,:] = self._data.channels[i], phases[j], counts[i,j]\n",
    "\n",
    "            np.savetxt(filename, array, fmt=['%u', '%.6f'] + [fmt])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CustomSignal.synthesise = synthesise\n",
    "CustomSignal._write = _write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = CustomSignal(data = _data,\n",
    "                        instrument = Instrument,\n",
    "                        background = background,\n",
    "                        interstellar = interstellar,\n",
    "                        cache = True,\n",
    "                        prefix='Instrument')\n",
    "\n",
    "\n",
    "\n",
    "likelihood = xpsi.Likelihood(star = star, signals = signal,\n",
    "                             num_energies=128,\n",
    "                             threads=1,\n",
    "                             externally_updated=False)\n",
    "\n",
    "\n",
    "for h in hot.objects:\n",
    "    h.set_phases(num_leaves = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\"\"\" Here I'm creating some synthetic data with the temperature grid, from 1 to 7.039 KeV (shape 100 )\n",
    "The exposure time for each data is 0.1 so that the total exposure time will be 100 s\n",
    "\"\"\"\n",
    "#for k in range(0,l):\n",
    "\n",
    "#likelihood.externally_updated = True  \n",
    "\n",
    "mass=2.1\n",
    "Req=12.3\n",
    "radius=.7\n",
    "\n",
    "#Telse=7.\n",
    "for k in range(len(temperature)):\n",
    "    s=int(seed[k])\n",
    "    %env GSL_RNG_SEED=$s\n",
    "    p_T=[mass,\n",
    "         Req,\n",
    "         0.8, # 1.5 for 3 KeV and 5. for 7 KeV\n",
    "         math.cos(15*np.pi/180),\n",
    "         0.6,\n",
    "         55*np.pi/180,\n",
    "         radius,\n",
    "         temperature[k],\n",
    "         1.41,              # BKG\n",
    "        7,               # BKG\n",
    "        3                # NH\n",
    "        ]\n",
    "\n",
    "    Instrument_kwargs = dict(exposure_time=b_bin,\n",
    "                             expected_background_counts=100.0,\n",
    "                             name='new_synthetic_case1_{}_{}_{}'.format(b_bin,k,radius),\n",
    "                             directory='./temp1.0.0/')\n",
    "\n",
    "    likelihood.synthesise(p_T, force=True, Instrument=Instrument_kwargs) # SEED=0\n",
    "    #print(p_T)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sampling took', (time.time()-start)/60, 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_syn=np.zeros((29,16))\n",
    "matrix_exp=np.zeros((29,16))\n",
    "const_syn=[]\n",
    "count_syn=[]\n",
    "const_exp=[]\n",
    "count_exp=[]\n",
    "\n",
    "for k in range(0,l):\n",
    "    syn=np.loadtxt('./temp1.0.0/new_synthetic_case1_{}_{}_{}_realisation.dat'.format(b_bin,k,radius))\n",
    "    exp=np.loadtxt('./temp1.0.0/new_synthetic_case1_{}_{}_{}_expectedcounts.dat'.format(b_bin,k,radius))\n",
    "    const_syn=np.append(const_syn,np.sum(syn))#-np.sum(b))\n",
    "    count_syn=np.append(count_syn,np.sum(syn))\n",
    "    matrix_syn +=syn\n",
    "    const_exp=np.append(const_exp,np.sum(exp))#-np.sum(b))\n",
    "    count_exp=np.append(count_exp,np.sum(exp))\n",
    "    matrix_exp +=exp\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the weighted mean\n",
    "\n",
    "\n",
    "## Photon flux:\n",
    "$N_{T} \\sim T^{3}$\n",
    "\n",
    "\n",
    "## mean Temperature:\n",
    "\n",
    "$T_{mean}=\\sum_{i=0}^{n} \\omega_{i}T_{i}$\n",
    "\n",
    "$\\omega_{i}=\\frac{n_{i}}{N_{total}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the Tmean\n",
    "coef=const_syn/np.sum(const_syn)\n",
    "Tmean=np.log10(np.sum(coef*np.power(10,temperature)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=10**temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log10(np.mean(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Tmean=np.log10(np.average(10**temperature,weights=coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_one_pulse(matrix, _data.phases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_syn.sum()/5000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=int(matrix_syn.sum()/5000.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_syn.sum()/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm lazy so I'm trying to automate a=everything :)\n",
    "\n",
    "#n=4               # How I decide to combine the burst so that the get the same number of counts\n",
    "#m=matrix_syn.sum()/n   # relatif number of count per combined burst\n",
    "\n",
    "\n",
    "\n",
    "cont=0\n",
    "timing=np.array([])\n",
    "for i in range(0,n-1):\n",
    "    #print(i)\n",
    "    globals()[\"M_syn{}\".format(i)]=np.zeros([29,16])\n",
    "    globals()[\"M_exp{}\".format(i)]=np.zeros([29,16])\n",
    "    #print(i)\n",
    "    timing=np.append(timing,cont)\n",
    "    #print(timing)\n",
    "    while globals()[\"M_syn{}\".format(i)].sum()<=5000.0:\n",
    "        ##print(count)\n",
    "        globals()[\"M_syn{}\".format(i)] +=np.loadtxt('./temp1.0.0/new_synthetic_case1_{}_{}_{}_realisation.dat'.format(b_bin,cont,radius))\n",
    "        globals()[\"M_exp{}\".format(i)] +=np.loadtxt('./temp1.0.0/new_synthetic_case1_{}_{}_{}_expectedcounts.dat'.format(b_bin,cont,radius))\n",
    "        #print(count,globals()[\"M{}\".format(i)].sum())\n",
    "        cont +=1\n",
    "        #print(cont)\n",
    "        \n",
    "globals()[\"M_syn{}\".format(n-1)]=np.zeros([29,16])\n",
    "globals()[\"M_exp{}\".format(n-1)]=np.zeros([29,16])\n",
    "timing=np.append(timing,cont)\n",
    "for i in range(cont,l):\n",
    "    globals()[\"M_syn{}\".format(n-1)] +=np.loadtxt('./temp1.0.0/new_synthetic_case1_{}_{}_{}_realisation.dat'.format(b_bin,i,radius))\n",
    "    globals()[\"M_exp{}\".format(n-1)] +=np.loadtxt('./temp1.0.0/new_synthetic_case1_{}_{}_{}_expectedcounts.dat'.format(b_bin,i,radius))\n",
    "   \n",
    "    cont +=1\n",
    "    #print(cont)\n",
    "timing=np.append(timing,cont)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#M_syn16.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_time=b_bin*(timing[1:]+timing[0:-1])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "13.75+(-13.75+22.5)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=np.zeros((29,16))\n",
    "# for k in range(199,299):\n",
    "#     a+=np.loadtxt('./temp/new_synthetic_case1_{}_{}_{}_realisation.dat'.format(b_bin,k,radius))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing*0.25/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#M_syn0.sum(),M_syn1.sum(),M_syn2.sum(),M_syn3.sum(),M_syn4.sum(),M_syn5.sum(),M_syn6.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_max=matrix_syn.sum(axis=0).max()\n",
    "exp_min=matrix_syn.sum(axis=0).min()\n",
    "alpha=(exp_max-exp_min)/2\n",
    "c=exp_min+alpha\n",
    "rms=alpha/(np.sqrt(2)*c)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,1,figsize=(9,7))\n",
    "syn=ax.imshow(matrix_syn,aspect=\"auto\",extent=[0,1,1,29], origin=\"lower\", cmap=cm.magma)\n",
    "ax.set_xlabel(\"Phases\")\n",
    "ax.set_ylabel(\"Channels\")\n",
    "anchored_text1 = AnchoredText(\"Case1\",loc=1)\n",
    "#ax[1].add_artist(anchored_text2)\n",
    "ax.add_artist(anchored_text1)\n",
    "plt.colorbar(syn,ax=ax)\n",
    "#plt.savefig(\"images/PPM_case1.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm=count_syn.max()/z_burst.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_z=np.linspace(0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,2,figsize=(15,5))\n",
    "ti=np.linspace(0,duration,count_syn.shape[0])\n",
    "ax[0].plot(ti, count_syn, \"tomato\",label=\"Synthetic burst\")\n",
    "ax[0].plot(ti, count_exp, \"red\", label=\"Expected burst\")\n",
    "ax[0].plot(z_time, norm*z_burst, \"k:\", label=\"GS-1826\")\n",
    "#ax[0].fill_between(ti, count_exp-np.sqrt(count_exp), count_exp+np.sqrt(count_exp), color=\"pink\")\n",
    "phase=np.linspace(0,1,16,endpoint=False)\n",
    "ax[1].plot(phase, matrix_syn.sum(axis=0),\"o\",color=\"k\", label=\"Synthetic burst\")\n",
    "ax[1].plot(phase, matrix_syn.sum(axis=0),\":\",color=\"k\")\n",
    "ax[1].plot(phase, matrix_exp.sum(axis=0), \"darkred\", label=\"Expected burst\")\n",
    "ax[1].fill_between(phase, matrix_exp.sum(axis=0)-np.sqrt(matrix_exp.sum(axis=0)), matrix_exp.sum(axis=0)+np.sqrt(matrix_exp.sum(axis=0)), color=\"pink\")\n",
    "ax[0].set_xlabel(\"Time (s)\")\n",
    "ax[0].set_ylabel(\"Total counts\")\n",
    "ax[1].set_xlabel(\"Phases\")\n",
    "ax[1].set_ylabel(\"Total counts\")\n",
    "anchored_text2 = AnchoredText(\"rms FA = \"+str(\"%.1f\" %rms)+\"%\",loc=8)\n",
    "anchored_text1 = AnchoredText(\"Total counts: \"+str(int(matrix_syn.sum())),loc=5)\n",
    "ax[1].add_artist(anchored_text2)\n",
    "ax[0].add_artist(anchored_text1)\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "#plt.savefig(\"images//light_curve_case1.pdf\")\n",
    "#plt.savefig(\"./generic_burst/hotspot_only/second/light_curve_case1.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_exp.sum()/150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generic_burst[50:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(generic_time[50:],(generic_burst[50:]-count[82:])**(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax=plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "# syn=ax[0].imshow(matrix,aspect=\"auto\",extent=[0,1,1,30], origin=\"lower\", cmap=cm.magma)\n",
    "# ax[0].set_xlabel(\"Phases\")\n",
    "# ax[0].set_ylabel(\"Channels\")\n",
    "# ax[0].title.set_text('Synthetic burst')\n",
    "\n",
    "# bur=ax[1].imshow(generic_pulse/good_burst.shape[0],aspect=\"auto\",extent=[0,1,0,28], origin=\"lower\", cmap=cm.magma)\n",
    "# ax[1].set_xlabel(\"Phases\")\n",
    "# ax[1].set_ylabel(\"Channels\")\n",
    "# ax[1].title.set_text('Average burst')\n",
    "\n",
    "# plt.colorbar(syn,ax=ax[0])\n",
    "# plt.colorbar(bur,ax=ax[1])\n",
    "# plt.savefig(\"generic_burst/hotspot_only/second/pulse_T_{}_{}_{}.png\".format(tmin,tmax, radius))\n",
    "# plt.savefig(\"generic_burst/hotspot_only/second/pulse_case1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,n):\n",
    "    globals()[\"exp_max{}\".format(i)]=globals()[\"M_exp{}\".format(i)].sum(axis=0).max()\n",
    "    globals()[\"exp_min{}\".format(i)]=globals()[\"M_exp{}\".format(i)].sum(axis=0).min()\n",
    "    globals()[\"alpha{}\".format(i)]=(globals()[\"exp_max{}\".format(i)]-globals()[\"exp_min{}\".format(i)])/2\n",
    "    globals()[\"c{}\".format(i)]=globals()[\"exp_min{}\".format(i)]+globals()[\"alpha{}\".format(i)]\n",
    "    globals()[\"rms{}\".format(i)]=globals()[\"alpha{}\".format(i)]/(np.sqrt(2)*globals()[\"c{}\".format(i)])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,n):\n",
    "    globals()[\"exp_max{}\".format(i)]=globals()[\"M_exp{}\".format(i)].sum(axis=0).max()\n",
    "    globals()[\"exp_min{}\".format(i)]=globals()[\"M_exp{}\".format(i)].sum(axis=0).min()\n",
    "    globals()[\"rms2{}\".format(i)]=100*(globals()[\"exp_max{}\".format(i)]-globals()[\"exp_min{}\".format(i)])/(np.sqrt(2)*(globals()[\"exp_max{}\".format(i)]+globals()[\"exp_min{}\".format(i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation error on rms\n",
    "\n",
    "for i in range(0,n):\n",
    "    globals()[\"exp_max{}\".format(i)]=globals()[\"M_exp{}\".format(i)].sum(axis=0).max()\n",
    "    globals()[\"exp_min{}\".format(i)]=globals()[\"M_exp{}\".format(i)].sum(axis=0).min()\n",
    "    globals()[\"err_rms{}\".format(i)]=np.sqrt((2*globals()[\"exp_max{}\".format(i)]*globals()[\"exp_min{}\".format(i)])/((globals()[\"exp_max{}\".format(i)]+globals()[\"exp_min{}\".format(i)])**3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=int(np.ceil(n/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(m,3, figsize=(15,20))\n",
    "#for k in range(0,m):\n",
    "for i in range(0,m):\n",
    "    x_syn=np.linspace(0,1,16,endpoint=False)\n",
    "    y_syn=globals()[\"M_syn{}\".format(3*i)].sum(axis=0)\n",
    "    x_exp=np.linspace(0,1,16,endpoint=False)\n",
    "    y_exp=globals()[\"M_exp{}\".format(3*i)].sum(axis=0)\n",
    "\n",
    "\n",
    "    globals()[\"text{}\".format(3*i)] = AnchoredText(\"% rms: \"+str(\"%.2f\" %(globals()[\"rms{}\".format(3*i)])), loc=8)\n",
    "    ax[i,0].plot(x_syn,y_syn,\"o\", color=\"k\")\n",
    "    ax[i,0].plot(x_syn,y_syn,\":\", color=\"k\")\n",
    "    ax[i,0].plot(x_exp,y_exp,\"-\", color=\"red\")\n",
    "    ax[i,0].fill_between(phase, y_exp-np.sqrt(y_exp), y_exp+np.sqrt(y_exp), color=\"pink\")\n",
    "    \n",
    "    #globals()[\"text{}\".format(3*i)] = AnchoredText(str(globals()[\"M_syn{}\".format(3*i)].sum()), loc=1)\n",
    "    ax[i,0].add_artist(globals()[\"text{}\".format(3*i)])\n",
    "\n",
    "\n",
    "\n",
    "    x_syn=np.linspace(0,1,16,endpoint=False)\n",
    "    y_syn=globals()[\"M_syn{}\".format(3*i+1)].sum(axis=0)\n",
    "    x_exp=np.linspace(0,1,16,endpoint=False)\n",
    "    y_exp=globals()[\"M_exp{}\".format(3*i+1)].sum(axis=0)\n",
    "\n",
    "\n",
    "    globals()[\"text{}\".format(3*i+1)] = AnchoredText(\"% rms: \"+str(\"%.2f\" %(globals()[\"rms{}\".format(3*i+1)])), loc=8)\n",
    "    ax[i,1].plot(x_syn,y_syn,\"o\", color=\"k\")\n",
    "    ax[i,1].plot(x_syn,y_syn,\":\", color=\"k\")\n",
    "    ax[i,1].plot(x_exp,y_exp,\"-\", color=\"red\")\n",
    "    ax[i,1].fill_between(phase, y_exp-np.sqrt(y_exp), y_exp+np.sqrt(y_exp), color=\"pink\")\n",
    "    #globals()[\"text{}\".format(3*i+1)] = AnchoredText(str(globals()[\"M_syn{}\".format(3*i+1)].sum()), loc=1)\n",
    "    ax[i,1].add_artist(globals()[\"text{}\".format(3*i+1)])\n",
    "\n",
    "\n",
    "    x_syn=np.linspace(0,1,16,endpoint=False)\n",
    "    y_syn=globals()[\"M_syn{}\".format(2*i+2)].sum(axis=0)\n",
    "    x_exp=np.linspace(0,1,16,endpoint=False)\n",
    "    y_exp=globals()[\"M_exp{}\".format(2*i+2)].sum(axis=0)\n",
    "\n",
    "\n",
    "    globals()[\"text{}\".format(3*i+2)] = AnchoredText(\"% rms: \"+str(\"%.2f\" %(globals()[\"rms{}\".format(3*i+2)])), loc=8)\n",
    "    ax[i,2].plot(x_syn,y_syn,\"o\", color=\"k\")\n",
    "    ax[i,2].plot(x_syn,y_syn,\":\", color=\"k\")\n",
    "    ax[i,2].plot(x_exp,y_exp,\"-\", color=\"red\")\n",
    "    ax[i,2].fill_between(phase, y_exp-np.sqrt(y_exp), y_exp+np.sqrt(y_exp), color=\"pink\")\n",
    "    #globals()[\"text{}\".format(3*i+2)] = AnchoredText(str(globals()[\"M_syn{}\".format(3*i+2)].sum()), loc=1)\n",
    "    ax[i,2].add_artist(globals()[\"text{}\".format(3*i+2)])\n",
    "\n",
    "\n",
    "\n",
    "    # ax[i].plot(xfit, fit(xfit,globals()[\"p{}\".format(i)][0],globals()[\"p{}\".format(i)][1]), \":\", color=\"k\")\n",
    "   # ax[i].add_artist(globals()[\"text{}\".format(i)])\n",
    "    #ax[i].set_xlabel(\"Phases\")\n",
    "#     ax[0].set_ylabel(\"Counts\")\n",
    "\n",
    "    #globals()[\"textburst{}\".format(i)] = AnchoredText(\"rms FA = \"+str(\"%.1f\" %(rms_burst[i]*100))+\"%\", loc=1)\n",
    "    #ax[1,i].plot(x,globals()[\"bu{}\".format(i)],\"o\", color=\"navy\")\n",
    "    #ax[1,i].plot(x, fitburst(x,globals()[\"pburst{}\".format(i)][0],globals()[\"pburst{}\".format(i)][1]), \":\",color=\"navy\")\n",
    "    #ax[1,i].add_artist(globals()[\"textburst{}\".format(i)])\n",
    "    #ax[1,i].set_xlabel(\"Phases\")\n",
    "\n",
    "#ax[0].set_ylabel(\"Counts\")\n",
    "#ax[1,0].set_ylabel(\"Counts\")\n",
    "#plt.savefig(\"generic_burst/hotspot_only/second/rmsFA_-{}_{}_{}.png\".format(tmin,tmax,radius))\n",
    "#plt.savefig(\"generic_burst/hotspot_only/second/rmsFA_case1.png\".format(tmin,tmax,radius))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(t,a,b):\n",
    "    return a*t+b\n",
    "\n",
    "r=[]\n",
    "for i in range(0,n):\n",
    "    r.append(globals()[\"rms{}\".format(i)])\n",
    "    \n",
    "fa,fb=curve_fit(fit,mid_time,r)\n",
    "xfit=np.linspace(0,150,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(t,a,b):\n",
    "    return a*t+b\n",
    "\n",
    "r=[]\n",
    "for i in range(0,n):\n",
    "    r.append(globals()[\"rms{}\".format(i)])\n",
    "    \n",
    "fa,fb=curve_fit(fit,mid_time,r)\n",
    "xfit=np.linspace(0,150,150)\n",
    "\n",
    "f, ax = plt.subplots(1,1) \n",
    "for i in range(0,n):\n",
    "    ax.plot(mid_time[i],globals()[\"rms{}\".format(i)],\"ko\")\n",
    "    #plt.errorbar(mid_time[i],globals()[\"rms{}\".format(i)],yerr=globals()[\"err_rms{}\".format(i)]*100,fmt=\"o\",color='black',ecolor=\"k\", elinewidth=None, capsize=4)\n",
    "\n",
    "anchored_text1 = AnchoredText(\"Case1\",loc=1)\n",
    "#ax[1].add_artist(anchored_text2)\n",
    "ax.add_artist(anchored_text1)\n",
    "\n",
    "ax.plot(xfit,fit(xfit,fa[0],fa[1]), \"k:\")\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_xlim(0,150.)\n",
    "ax.set_ylim(0,20.)\n",
    "ax.set_ylabel(\"% rms\")\n",
    "#plt.savefig(\"images/rms_case1.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.system('spd-say \"Done\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt(\"../../data/data_case1_0_0.dat\",matrix_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_one_pulse(np.loadtxt(\"../../data/data_case1_0_0.dat\"), _data.phases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.randint(1,15, size=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.linspace(1,10000,10000000)\n",
    "plt.plot(x,x*x+x*np.sqrt(x*x-0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
