#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Jul 27 13:31:21 2022

@author: bas
"""


import numpy as np
from astropy.io import fits
from numpy import ones, zeros
from scipy import interpolate

t__e = np.arange(40.0, 202.0, 4.0) #actual range is 40-200 imaginaty units, ~20-100 keV (Te(keV)*1000/511keV is here)
t__bb = np.arange(0.00015, 0.0031, 0.00015) #this one is non-physical, we went for way_to_low Tbbs here, I will most probably delete results from too small Tbbs. This is Tbb(keV)/511keV, so these correspond to 0.07 - 1.5 keV, but our calculations don't work correctly for Tbb<<0.5 keV
tau__t = np.arange(0.5, 3.55, 0.1) 

# NEnergy_i = 150
# NZenith_i = 9

# I am unable to reproduce the eneries from the bin file:
# with open('/home/bas/Documents/Projects/x-psi/pulse_profiling_bobrikova/Compx_150.bin','rb') as file:
#     x = list(file.read())

# So I use the code she sent.
x_l, x_u = -3.7, .3 # lower and upper bounds of the log_10 energy span
NEnergy = 150 # 50# 101 # number of energy points (x)
IntEnergy = np.logspace(x_l,x_u,NEnergy), np.log(1e1)*(x_u-x_l)/(NEnergy-1.) # sample points and weights for integrations over the spectrum computing sorce function
Energy,x_weight=IntEnergy

# I am unable to reproduce the angles from Anna's forwarded code:
# NMu = 9 # 20# 15 # number of propagation zenith angle cosines (\mu) [0,1]
# NZenith = 2*NMu # number of propagation zenith angles (z) [0,pi]
# IntZenith = np.polynomial.legendre.leggauss(NZenith) #  sample points and weights for integrations over zenith angle in positive and negative directions together
# mu,mu_weight=IntZenith

# data she sent.
# mu = [0.0159199, 0.0819844, 0.193314, 0.337873, 0.5, 0.662127, 0.806686, 0.918016, 0.98408]

# Updated code

from numpy.polynomial.legendre import leggauss

def init_mu(n = 3):
        NMu = n # number of propagation zenith angle cosines (\mu) [0,1]
        NZenith = 2*NMu # number of propagation zenith angles (z) [0,pi]
        mu = np.empty(NZenith)
        #mu = Array{Float64}(undef,NZenith)
        #mu_weight = Array{Float64}(undef,NZenith)
        m2,mw = leggauss(NMu)
        mu[:NMu] = (m2 - 1.)/2
        mu[NMu:NZenith] = (m2 + 1.)/2
        
        #mu_weight[1:NMu] = (mw)./2
        #mu_weight[NMu+1:2NMu] = (mw)./2
        #global Î¼_grid = n, 2n, mu, mu_weight
        
        return mu[NMu:NZenith]

mu = init_mu(9)



I_mighty = ones((len(t__e), len(t__bb), len(tau__t), len(Energy), len(mu))) #5D Intensity tensor[Te,Tbb,tau_t, Energy, Mu]
Q_mighty = ones((len(t__e), len(t__bb), len(tau__t), len(Energy), len(mu))) #5D Q-parameter tensor[Te,Tbb,tau_t, Energy, Mu]


def reading_table(): #routine that just reads fits tables to I_mighty and Q_mighty
    path='/home/bas/Documents/Projects/x-psi/pulse_profiling_bobrikova/'
    global I_mighty
    global Q_mighty
    p=0 #as we will not go over lenght_Te but just over values within t__e array, we'll need a counter for index corr. to Te
    for i in t__e:
        hdu = fits.open(path+'CompSlab_%s.fits' %(i), mode='update')
        print('With CompSlab_%s.fits still works' %(i)) #just to see sth on the screen while the files are being opened
        for ii in range(0,len(t__bb)): #Tbb
            for iii in range(0,16): #that's tau_t
                science_data = hdu[(iii)*len(t__bb)+ii+1].data #this messy index leads to the correct "list" within FITS file
                data = np.transpose(science_data.field(1)) #we need to transpose them, because tables were generated by julia and read in python, and there languages have different "majoring" in rows or columns, afaik
                data2 = np.transpose(science_data.field(0))
                for kk in range(0, len(Energy)): #energy
                    for kkk in range(0, len(mu)): #zenith angles
                        I_mighty[p, ii, iii, kk, kkk] = data[kk, kkk+1]#+1 is they way to avoid saving the first column of the fits files, which is accidentally always zero
                        Q_mighty[p, ii, iii, kk, kkk] = data2[kk, kkk+1]
        p +=1
    #now we do the same for 2nd and later 3rd table corr. to the same Te. 
    #Generally, 1st table contain data for small tau_T, 2nd one for middle tau_T, 3rd one for big tau_T. 
    p=0
    for i in t__e:
        hdu = fits.open(path+'CompSlab_bigTe_%s.fits' %(i), mode='update')
        print('With CompSlab_bigTe_%s.fits still works' %(i))
        for ii in range(0,len(t__bb)):
            for iii in range(0,10):
                science_data = hdu[(iii)*len(t__bb)+ii+1].data 
                data = np.transpose(science_data.field(1))
                data2 = np.transpose(science_data.field(0))
                for kk in range(0, len(Energy)):
                    for kkk in range(0, len(mu)):
                        I_mighty[p, ii, iii+16, kk, kkk] = data[kk, kkk+1]
                        Q_mighty[p, ii, iii+16, kk, kkk] = data2[kk, kkk+1]
        p +=1
    p=0            
    for i in t__e:
        hdu = fits.open(path+'CompSlab_hugeT_%s.fits' %(i), mode='update')
        print('With CompSlab_hugeT_%s.fits still works' %(i)) 
        for ii in range(0,len(t__bb)):
            for iii in range(0,5):
                science_data = hdu[(iii)*len(t__bb)+ii+1].data 
                data = np.transpose(science_data.field(1))
                data2 = np.transpose(science_data.field(0))
                for kk in range(0, len(Energy)):
                    for kkk in range(0, len(mu)):
                        I_mighty[p, ii, iii+26, kk, kkk] = data[kk, kkk+1]
                        Q_mighty[p, ii, iii+26, kk, kkk] = data2[kk, kkk+1]
        p +=1

reading_table()

#%%




# I(E < mu < tau < tbb < te)

INDEX = 0
intensities_size = 1
for shape in I_mighty.shape:
    intensities_size *= shape

NSX = np.empty((intensities_size,6))

for m in range(len(t__e)):
    for l in range(len(t__bb)):
        for k in range(len(tau__t)):
            for j in range(len(mu)):
                for i in range(len(Energy)):
                    NSX[INDEX,0] = Energy[i]
                    NSX[INDEX,1] = mu[j]
                    NSX[INDEX,2] = tau__t[k]
                    NSX[INDEX,3] = t__bb[l]
                    NSX[INDEX,4] = t__e[m]
                    NSX[INDEX,5] = I_mighty[m,l,k,i,j]
                    INDEX += 1


path_save='/home/bas/Documents/Projects/x-psi/model_datas/bobrikova/'
np.savez_compressed(path_save+'Bobrikova_compton_slab.npz', NSX)











